{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50a28a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/surbhisharma/rag_assesment/.venv1/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509d97eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a64ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (4.56.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: filelock in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (3.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/surbhisharma/rag_assesment/.venv1/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5c1b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (4.56.1)\n",
      "Requirement already satisfied: datasets in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (4.0.0)\n",
      "Requirement already satisfied: peft in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: torch in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: filelock in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: requests in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pandas in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from peft) (1.10.1)\n",
      "Requirement already satisfied: psutil in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: networkx in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/surbhisharma/rag_assesment/.venv1/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers datasets peft torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b4ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipykernel\n",
      "  Using cached ipykernel-6.30.1-py3-none-any.whl (117 kB)\n",
      "Collecting jupyter-client>=8.0.0\n",
      "  Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "Collecting comm>=0.1.1\n",
      "  Using cached comm-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "Collecting appnope>=0.1.2\n",
      "  Using cached appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\n",
      "Collecting tornado>=6.2\n",
      "  Using cached tornado-6.5.2-cp39-abi3-macosx_10_9_x86_64.whl (440 kB)\n",
      "Collecting nest-asyncio>=1.4\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting traitlets>=5.4.0\n",
      "  Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "Requirement already satisfied: packaging>=22 in /Users/surbhisharma/rag_assesment/services/embedding_service/venv/lib/python3.9/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /Users/surbhisharma/rag_assesment/services/embedding_service/venv/lib/python3.9/site-packages (from ipykernel) (7.0.0)\n",
      "Collecting pyzmq>=25\n",
      "  Using cached pyzmq-27.0.2-cp39-cp39-macosx_10_15_universal2.whl (1.3 MB)\n",
      "Collecting debugpy>=1.6.5\n",
      "  Using cached debugpy-1.8.16-cp39-cp39-macosx_14_0_x86_64.whl (2.1 MB)\n",
      "Collecting ipython>=7.23.1\n",
      "  Using cached ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "Collecting matplotlib-inline>=0.1\n",
      "  Using cached matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Collecting jupyter-core!=5.0.*,>=4.12\n",
      "  Using cached jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
      "Collecting prompt-toolkit<3.1.0,>=3.0.41\n",
      "  Using cached prompt_toolkit-3.0.52-py3-none-any.whl (391 kB)\n",
      "Collecting jedi>=0.16\n",
      "  Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting stack-data\n",
      "  Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting pexpect>4.3\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/surbhisharma/rag_assesment/services/embedding_service/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.15.0)\n",
      "Collecting decorator\n",
      "  Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: exceptiongroup in /Users/surbhisharma/rag_assesment/services/embedding_service/venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.3.0)\n",
      "Collecting pygments>=2.4.0\n",
      "  Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "Collecting parso<0.9.0,>=0.8.4\n",
      "  Using cached parso-0.8.5-py2.py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/surbhisharma/rag_assesment/services/embedding_service/venv/lib/python3.9/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Collecting importlib-metadata>=4.8.3\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting zipp>=3.20\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Collecting platformdirs>=2.5\n",
      "  Using cached platformdirs-4.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting ptyprocess>=0.5\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/surbhisharma/rag_assesment/services/embedding_service/venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Collecting pure-eval\n",
      "  Using cached pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Using cached asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting executing>=1.2.0\n",
      "  Using cached executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
      "Installing collected packages: zipp, wcwidth, traitlets, pure-eval, ptyprocess, platformdirs, parso, executing, asttokens, tornado, stack-data, pyzmq, pygments, prompt-toolkit, pexpect, matplotlib-inline, jupyter-core, jedi, importlib-metadata, decorator, nest-asyncio, jupyter-client, ipython, debugpy, comm, appnope, ipykernel\n",
      "Successfully installed appnope-0.1.4 asttokens-3.0.0 comm-0.2.3 debugpy-1.8.16 decorator-5.2.1 executing-2.2.1 importlib-metadata-8.7.0 ipykernel-6.30.1 ipython-8.18.1 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.8.1 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 parso-0.8.5 pexpect-4.9.0 platformdirs-4.4.0 prompt-toolkit-3.0.52 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.19.2 pyzmq-27.0.2 stack-data-0.6.3 tornado-6.5.2 traitlets-5.14.3 wcwidth-0.2.13 zipp-3.23.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/surbhisharma/rag_assesment/services/embedding_service/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ipykernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7facbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf1c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data = {\n",
    "    \"question\": [\"What is the capital of France?\", \"Who wrote '1984'?\", \"What is 2 + 2?\"],\n",
    "    \"answer\": [\"Paris\", \"George Orwell\", \"4\"]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4aca73d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 73,728 || all params: 81,987,072 || trainable%: 0.0899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "tokenizer.pad_token = '[PAD]'\n",
    "# Configure LoRA adapter\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Example: attach LoRA to a GPT2 model\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\"],  # GPT2 attention layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()  # check which params are trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4831b3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.transformer.wte.weight False\n",
      "base_model.model.transformer.wpe.weight False\n",
      "base_model.model.transformer.h.0.ln_1.weight False\n",
      "base_model.model.transformer.h.0.ln_1.bias False\n",
      "base_model.model.transformer.h.0.attn.c_attn.base_layer.weight False\n",
      "base_model.model.transformer.h.0.attn.c_attn.base_layer.bias False\n",
      "base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight True\n",
      "base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight True\n",
      "base_model.model.transformer.h.0.attn.c_proj.weight False\n",
      "base_model.model.transformer.h.0.attn.c_proj.bias False\n",
      "base_model.model.transformer.h.0.ln_2.weight False\n",
      "base_model.model.transformer.h.0.ln_2.bias False\n",
      "base_model.model.transformer.h.0.mlp.c_fc.weight False\n",
      "base_model.model.transformer.h.0.mlp.c_fc.bias False\n",
      "base_model.model.transformer.h.0.mlp.c_proj.weight False\n",
      "base_model.model.transformer.h.0.mlp.c_proj.bias False\n",
      "base_model.model.transformer.h.1.ln_1.weight False\n",
      "base_model.model.transformer.h.1.ln_1.bias False\n",
      "base_model.model.transformer.h.1.attn.c_attn.base_layer.weight False\n",
      "base_model.model.transformer.h.1.attn.c_attn.base_layer.bias False\n",
      "base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight True\n",
      "base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight True\n",
      "base_model.model.transformer.h.1.attn.c_proj.weight False\n",
      "base_model.model.transformer.h.1.attn.c_proj.bias False\n",
      "base_model.model.transformer.h.1.ln_2.weight False\n",
      "base_model.model.transformer.h.1.ln_2.bias False\n",
      "base_model.model.transformer.h.1.mlp.c_fc.weight False\n",
      "base_model.model.transformer.h.1.mlp.c_fc.bias False\n",
      "base_model.model.transformer.h.1.mlp.c_proj.weight False\n",
      "base_model.model.transformer.h.1.mlp.c_proj.bias False\n",
      "base_model.model.transformer.h.2.ln_1.weight False\n",
      "base_model.model.transformer.h.2.ln_1.bias False\n",
      "base_model.model.transformer.h.2.attn.c_attn.base_layer.weight False\n",
      "base_model.model.transformer.h.2.attn.c_attn.base_layer.bias False\n",
      "base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight True\n",
      "base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight True\n",
      "base_model.model.transformer.h.2.attn.c_proj.weight False\n",
      "base_model.model.transformer.h.2.attn.c_proj.bias False\n",
      "base_model.model.transformer.h.2.ln_2.weight False\n",
      "base_model.model.transformer.h.2.ln_2.bias False\n",
      "base_model.model.transformer.h.2.mlp.c_fc.weight False\n",
      "base_model.model.transformer.h.2.mlp.c_fc.bias False\n",
      "base_model.model.transformer.h.2.mlp.c_proj.weight False\n",
      "base_model.model.transformer.h.2.mlp.c_proj.bias False\n",
      "base_model.model.transformer.h.3.ln_1.weight False\n",
      "base_model.model.transformer.h.3.ln_1.bias False\n",
      "base_model.model.transformer.h.3.attn.c_attn.base_layer.weight False\n",
      "base_model.model.transformer.h.3.attn.c_attn.base_layer.bias False\n",
      "base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight True\n",
      "base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight True\n",
      "base_model.model.transformer.h.3.attn.c_proj.weight False\n",
      "base_model.model.transformer.h.3.attn.c_proj.bias False\n",
      "base_model.model.transformer.h.3.ln_2.weight False\n",
      "base_model.model.transformer.h.3.ln_2.bias False\n",
      "base_model.model.transformer.h.3.mlp.c_fc.weight False\n",
      "base_model.model.transformer.h.3.mlp.c_fc.bias False\n",
      "base_model.model.transformer.h.3.mlp.c_proj.weight False\n",
      "base_model.model.transformer.h.3.mlp.c_proj.bias False\n",
      "base_model.model.transformer.h.4.ln_1.weight False\n",
      "base_model.model.transformer.h.4.ln_1.bias False\n",
      "base_model.model.transformer.h.4.attn.c_attn.base_layer.weight False\n",
      "base_model.model.transformer.h.4.attn.c_attn.base_layer.bias False\n",
      "base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight True\n",
      "base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight True\n",
      "base_model.model.transformer.h.4.attn.c_proj.weight False\n",
      "base_model.model.transformer.h.4.attn.c_proj.bias False\n",
      "base_model.model.transformer.h.4.ln_2.weight False\n",
      "base_model.model.transformer.h.4.ln_2.bias False\n",
      "base_model.model.transformer.h.4.mlp.c_fc.weight False\n",
      "base_model.model.transformer.h.4.mlp.c_fc.bias False\n",
      "base_model.model.transformer.h.4.mlp.c_proj.weight False\n",
      "base_model.model.transformer.h.4.mlp.c_proj.bias False\n",
      "base_model.model.transformer.h.5.ln_1.weight False\n",
      "base_model.model.transformer.h.5.ln_1.bias False\n",
      "base_model.model.transformer.h.5.attn.c_attn.base_layer.weight False\n",
      "base_model.model.transformer.h.5.attn.c_attn.base_layer.bias False\n",
      "base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight True\n",
      "base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight True\n",
      "base_model.model.transformer.h.5.attn.c_proj.weight False\n",
      "base_model.model.transformer.h.5.attn.c_proj.bias False\n",
      "base_model.model.transformer.h.5.ln_2.weight False\n",
      "base_model.model.transformer.h.5.ln_2.bias False\n",
      "base_model.model.transformer.h.5.mlp.c_fc.weight False\n",
      "base_model.model.transformer.h.5.mlp.c_fc.bias False\n",
      "base_model.model.transformer.h.5.mlp.c_proj.weight False\n",
      "base_model.model.transformer.h.5.mlp.c_proj.bias False\n",
      "base_model.model.transformer.ln_f.weight False\n",
      "base_model.model.transformer.ln_f.bias False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)  # LoRA layers should have True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63edfd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3/3 [00:00<00:00, 224.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    # Example: Concatenate question and answer\n",
    "    model_inputs = tokenizer(examples['question'], truncation=True, padding='max_length', max_length=128)\n",
    "    \n",
    "    # Use the same tokens for labels (for causal LM)\n",
    "    model_inputs['labels'] = model_inputs['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f4e272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.56.1\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages\n",
      "Requires: packaging, tqdm, numpy, pyyaml, huggingface-hub, tokenizers, safetensors, requests, regex, filelock\n",
      "Required-by: sentence-transformers, peft\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e14f2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14.005000</td>\n",
       "      <td>13.872079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.167600</td>\n",
       "      <td>13.867644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13.374300</td>\n",
       "      <td>13.863847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.243600</td>\n",
       "      <td>13.860340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>13.961400</td>\n",
       "      <td>13.857364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>13.865600</td>\n",
       "      <td>13.854894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13.968300</td>\n",
       "      <td>13.852844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>13.645400</td>\n",
       "      <td>13.851298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>13.531600</td>\n",
       "      <td>13.850308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13.564400</td>\n",
       "      <td>13.849885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=13.642737102508544, metrics={'train_runtime': 7.3232, 'train_samples_per_second': 4.097, 'train_steps_per_second': 2.731, 'total_flos': 981561507840.0, 'train_loss': 13.642737102508544, 'epoch': 10.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_distilgpt2\",\n",
    "    learning_rate=2e-5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=1,                # Log every step\n",
    "    logging_strategy=\"steps\",       # Use step-based logging\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51229292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages/peft/utils/save_and_load.py:300: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./lora_distilgpt2/tokenizer_config.json',\n",
       " './lora_distilgpt2/special_tokens_map.json',\n",
       " './lora_distilgpt2/vocab.json',\n",
       " './lora_distilgpt2/merges.txt',\n",
       " './lora_distilgpt2/added_tokens.json',\n",
       " './lora_distilgpt2/tokenizer.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./lora_distilgpt2\")\n",
    "tokenizer.save_pretrained(\"./lora_distilgpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7415ee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surbhisharma/rag_assesment/.venv1/lib/python3.9/site-packages/peft/utils/save_and_load.py:546: UserWarning: Some weights of PeftModelForCausalLM were not initialized from the model checkpoint and are being ignored because you passed `ignore_mismatched_sizes=True`: - base_model.model.lm_head.weight: found shape torch.Size([50258, 768]) in the checkpoint and torch.Size([50257, 768]) in the model instantiated\n",
      "- base_model.model.transformer.wte.weight: found shape torch.Size([50258, 768]) in the checkpoint and torch.Size([50257, 768]) in the model instantiated.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question with only the factual answer:\n",
      "Q: What is the capital of France?\n",
      "A: The capital of France is the capital of France.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load base model and tokenizer\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "# Set pad_token to eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Resize embeddings if needed\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Load LoRA adapter\n",
    "model = PeftModel.from_pretrained(base_model, \"./lora_distilgpt2\", ignore_mismatched_sizes=True)\n",
    "\n",
    "# Prepare input with attention mask\n",
    "inputs = tokenizer(\"What is the capital of France?\", return_tensors=\"pt\", padding=True)\n",
    "input_ids = inputs.input_ids\n",
    "attention_mask = inputs.attention_mask\n",
    "\n",
    "prompt = \"Answer the following question with only the factual answer:\\nQ: What is the capital of France?\\nA:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "output_ids = model.generate(inputs.input_ids, max_new_tokens=10, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1 (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
